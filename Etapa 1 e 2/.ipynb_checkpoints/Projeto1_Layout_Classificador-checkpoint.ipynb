{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ant√¥nio Amaral\n",
    "\n",
    "Nome: Gabriel Penna\n",
    "\n",
    "Nome: Caio Garcia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo Fun√ß√£o Magica iPython\n",
    "%matplotlib inline\n",
    "#Importanto Pandas\n",
    "import pandas as pd\n",
    "#Importando MatPlotLib e Numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Importando Sistema Operacional\n",
    "import os\n",
    "#Importando RE\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "/Users/antonioamaralegydiomartins/Desktop/Ant√¥nio/GitHub - Pessoal/INSPER/CDados_Projeto1/Etapa 1 e 2\n"
     ]
    }
   ],
   "source": [
    "#Checando Diret√≥rio que ser√° trabalhado:\n",
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulas Utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace (frase,tabela_rel, tabela_irrel,nao_repetentes,len_rel,len_irrel):\n",
    "    #Definindo lista de probabilidades\n",
    "    probR_list=[]\n",
    "    probIr_list=[]\n",
    "    #Separando a Frase em elementos\n",
    "    splt = frase.split()\n",
    "    #For para reconhecer a quantidade \n",
    "    for palavra in splt:\n",
    "        if palavra not in tabela_rel:\n",
    "            qtR = 1\n",
    "        else:\n",
    "            qtR = tabela_rel[palavra] + 1\n",
    "        if palavra not in tabela_irrel:\n",
    "            qtIr = 1\n",
    "        else:\n",
    "            qtIr = tabela_irrel[palavra] + 1\n",
    "        #Definindo divisores\n",
    "        div1 = len_rel + len(nao_repetentes)\n",
    "        div2 = len_irrel + len(nao_repetentes)\n",
    "        #CCalculo de Laplace\n",
    "        probR_list.append(qtR/div1)\n",
    "        probIr_list.append(qtIr/div2)\n",
    "    return (probR_list,probIr_list)\n",
    "\n",
    "def cleanup(texto):\n",
    "\n",
    "    temp = texto.lower()\n",
    "\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "\n",
    "    temp = re.sub('[()!?„Öã;:,/^~‚ôÇÔ∏è*=&-]', ' ', temp)\n",
    "\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "\n",
    "    temp = re.sub(\"[z0-9]\",\" \", temp)\n",
    "\n",
    "    temp = re.sub('\\\\\\\\\\\\\\\\n',\" \", temp)\n",
    "\n",
    "    temp = re.sub('\\\\\\\\',\" \", temp)\n",
    "\n",
    "    temp = re.sub('\\ ',\" \", temp)\n",
    "    \n",
    "    temp = re.sub(\"√©\",\"e\",temp)\n",
    "    \n",
    "    temp = re.sub(\"√£\",\"a\",temp)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo Arquivo que ser√° trabalhado\n",
    "filename = 'yakult-final.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@colchoesueli a m√©dica passou lactobacilos p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algu√©m compra yakult pra mim por deus</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amanh√£ vou fazer aquele drink de morango, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomando um yakult no meio da rua üí™</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48 horas e estou sobrevivendo com;\\\\\\\\nmei...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0    @colchoesueli a m√©dica passou lactobacilos p...            1.0\n",
       "1            algu√©m compra yakult pra mim por deus              0.0\n",
       "2      amanh√£ vou fazer aquele drink de morango, ...            0.0\n",
       "3               tomando um yakult no meio da rua üí™              1.0\n",
       "4      48 horas e estou sobrevivendo com;\\\\\\\\nmei...            1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando Excel dentro da Vari√°vel Trainamento\n",
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@otavio_amaral18 √© uma del√≠cia juro, desce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o c√©rebro √© muito impressionante, ontem eu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fenicolli02 quem q pede gole do yakult???...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@thamaramaia5 @adrianommartins @taaayrd @t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sdds das mamis juntas brindando yakult @fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0      @otavio_amaral18 √© uma del√≠cia juro, desce...              1\n",
       "1      o c√©rebro √© muito impressionante, ontem eu...              1\n",
       "2      @fenicolli02 quem q pede gole do yakult???...              0\n",
       "3      @thamaramaia5 @adrianommartins @taaayrd @t...              0\n",
       "4      sdds das mamis juntas brindando yakult @fe...              0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando Excel dentro da Vari√°vel Teste\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento Naive-Bayles --- Classificador Autom√°tico de Sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto que foi escolhido para ser analizado foi o yakult, a famosa bebida fermentada japonesa, o grupo levou em considera√ß√£o a emiss√£o de opini√£o na hora de montar o seu classificador. Sendo assim se houve a emiss√£o de uma uma opini√£o, sendo ben√©fica ou n√£o, o Tweet √© considerado relevante, por√©m se houver a emiss√£o de uma opini√£o que n√£o corresponde ao produto, ou n√£o houve a emiss√£o de uma opini√£o o Tweet √© considerado irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### - Definindo Relev√¢ncia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                algu√©m compra yakult pra mim por deus  \n",
       "2          amanh√£ vou fazer aquele drink de morango, ...\n",
       "5          @madrugatina sei que vc n√£o bebe, ent√£o va...\n",
       "6          meu lindo :( quero ver ele fazendo batida ...\n",
       "7          nadei igual um desgra√ßado, agora comi bata...\n",
       "                             ...                        \n",
       "482        talvez eu fa√ßa aquela bebida de morango co...\n",
       "486        meu maior sonho atualmente √© um yakult veg...\n",
       "492        @bcamoezi esses dias comprei couve, alface...\n",
       "495        ontem eu comi...\\\\\\\\np√£o na chapa\\\\\\\\nstak...\n",
       "497        ontem eu cheguei de madrugada em casa e fi...\n",
       "Name: Treinamento, Length: 285, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo quais s√£o os Tweets com classifica√ß√£o Irrelevante, dentro da Sheet Treinamento\n",
    "Irrelevantes=train.loc[train['Classifica√ß√£o']==0,'Treinamento']\n",
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @colchoesueli a m√©dica passou lactobacilos p...\n",
       "3                   tomando um yakult no meio da rua üí™  \n",
       "4          48 horas e estou sobrevivendo com;\\\\\\\\nmei...\n",
       "14         minha sogra fala mais que a mulher do yaku...\n",
       "15         √∫ltima coisa q comeu ‚Äî tomei um yakult de ...\n",
       "                             ...                        \n",
       "490        a garrafinha de yakult √© mt pequena, mano,...\n",
       "491        @caarolmario bebida de yakult com corote (...\n",
       "493        acabei de ingerir isso aqui, me disseram q...\n",
       "494        bernardo aprendeu a tomar yakult de canudi...\n",
       "496      bolo: red velvet ou chocolate\\\\\\\\ndoce: chee...\n",
       "Name: Treinamento, Length: 213, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo quais s√£o os Tweets com classifica√ß√£o Relevante, dentro da Sheet Treinamento\n",
    "Relevantes=train.loc[train['Classifica√ß√£o']==1,'Treinamento']\n",
    "Relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### - Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando vari√°veis e realizando limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo texto_relevante, como a jun√ß√£o de todos os Tweets relevantes\n",
    "texto_relevante=' '.join(Relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo texto_irrelevante como a jun√ß√£o de todos os Tweets irrelevantes\n",
    "texto_irrelevante=' '.join(Irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passando ambos os textos pela fun√ß√£o Cleanup, e convertendo todas as letras para Lowercase\n",
    "texto_limpo_relevante=cleanup(texto_relevante).lower()\n",
    "texto_limpo_irrelevante=cleanup(texto_irrelevante).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo as strings limpas em objetos do tipo pd.series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_relevantes = texto_limpo_relevante.split()\n",
    "serie_rel = pd.Series(palavras_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = texto_limpo_irrelevante.split()\n",
    "serie_irrel = pd.Series(palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornando os objetos transformados acima em series relativas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irel = serie_rel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_rrel = serie_irrel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Irrelevantes: 1.0 e de Relevantes: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "#Checando porcentagem das listas\n",
    "print(\"Porcentagem de Irrelevantes: {0} e de Relevantes: {1}\".format(serie_irel.sum(),serie_rrel.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montando serie com todas as palavras que aparecem em todos os Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_rel = serie_rel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrel = serie_irrel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_rel_rel = serie_rel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_rel_irrel = serie_irrel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Somando Palavras Relevantes e Irrelevantes para criar um dicion√°rio de palavras\n",
    "todas = texto_limpo_relevante + texto_limpo_irrelevante\n",
    "#Criando serie_total\n",
    "total_palavras = todas.split()\n",
    "serie_total = pd.Series(total_palavras)\n",
    "#Criando a tabela total de palavras\n",
    "tabela_total = serie_total.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procentagem da Tabela de Irrelevantes: 4222 e de Relevantes: 3230\n"
     ]
    }
   ],
   "source": [
    "print(\"Procentagem da Tabela de Irrelevantes: {0} e de Relevantes: {1}\".format(tabela_irrel.sum(),tabela_rel.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando vari√°veis que representam a soma das tabelas irrel e rel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelPal = tabela_rel.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrrelPal = tabela_irrel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalPal = tabela_total.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrindo a Probabilidade de ser uma palavra Relevante e Irrelevante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de uma palavra ser Irrelevante: 0.5665593129361245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probI=IrrelPal/TotalPal\n",
    "print(\"A probabilidade de uma palavra ser Irrelevante: {0}\".format(probI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de uma palavra ser Relevante: 0.43344068706387545\n"
     ]
    }
   ],
   "source": [
    "probR=RelPal/TotalPal\n",
    "print(\"A probabilidade de uma palavra ser Relevante: {0}\".format(probR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tabela_total = serie_total.tolist()\n",
    "nao_repetentes = set(lista_tabela_total)\n",
    "nao_repetentes = pd.DataFrame(nao_repetentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gosto muito estou viciado abri geladeira'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frase = \"gosto muito estou viciado abri geladeira\"\n",
    "Frase = cleanup(Frase).lower()\n",
    "Frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_rel = len(tabela_rel)\n",
    "len_irrel = len(tabela_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "probfR = laplace(Frase, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[0]\n",
    "probfIr = laplace(Frase, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[1]\n",
    " \n",
    "pR = 1\n",
    "pIr = 1\n",
    "\n",
    "for e in range(len(probfR)):\n",
    "    pR = pR * probfR[e]\n",
    "    pIr = pIr * probfIr[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante\n"
     ]
    }
   ],
   "source": [
    "if pR > pIr:\n",
    "    print(\"Relevante\")\n",
    "else:\n",
    "    print(\"Irrelevante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = []\n",
    "for e in test[\"Teste\"]:\n",
    "    text_clean_test = cleanup(e).lower()\n",
    "    Tweets.append(text_clean_test)\n",
    "    \n",
    "List_Relevancia = []\n",
    "for Tweet in Tweets:\n",
    "    probfR2 = laplace(Tweet, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[0]\n",
    "    probfIr2 = laplace(Tweet, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[1]\n",
    "    pR2 = 1\n",
    "    pIr2 = 1\n",
    "    for e in range(len(probfR2)):\n",
    "        pR2 = pR2 * probfR2[e]\n",
    "        pIr2 = pIr2 * probfIr2[e]\n",
    "    if pR2 > pIr2:\n",
    "        List_Relevancia.append(1)\n",
    "    else:\n",
    "        List_Relevancia.append(0)\n",
    "        \n",
    "test[\"Classificador\"] = List_Relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_Relevancia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@otavio_amaral18 √© uma del√≠cia juro, desce...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o c√©rebro √© muito impressionante, ontem eu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fenicolli02 quem q pede gole do yakult???...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@thamaramaia5 @adrianommartins @taaayrd @t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sdds das mamis juntas brindando yakult @fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>minha depress√£o come√ßou quando eu soube q nem...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>queria amanhecer na buia hoje, mas pelo jeito...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>a geladeira cheia de yakult, √© pra isso que e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>‚úçÔ∏è‚úçÔ∏è‚úçÔ∏èexperimentar yakult quente com soro fis...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tomei umas 4 garrafinhas de yakult hj üò®</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Classifica√ß√£o  \\\n",
       "0        @otavio_amaral18 √© uma del√≠cia juro, desce...              1   \n",
       "1        o c√©rebro √© muito impressionante, ontem eu...              1   \n",
       "2        @fenicolli02 quem q pede gole do yakult???...              0   \n",
       "3        @thamaramaia5 @adrianommartins @taaayrd @t...              0   \n",
       "4        sdds das mamis juntas brindando yakult @fe...              0   \n",
       "..                                                 ...            ...   \n",
       "295   minha depress√£o come√ßou quando eu soube q nem...              1   \n",
       "296   queria amanhecer na buia hoje, mas pelo jeito...              1   \n",
       "297   a geladeira cheia de yakult, √© pra isso que e...              1   \n",
       "298   ‚úçÔ∏è‚úçÔ∏è‚úçÔ∏èexperimentar yakult quente com soro fis...              0   \n",
       "299            tomei umas 4 garrafinhas de yakult hj üò®              1   \n",
       "\n",
       "     Classificador  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "..             ...  \n",
       "295              0  \n",
       "296              0  \n",
       "297              1  \n",
       "298              1  \n",
       "299              0  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
