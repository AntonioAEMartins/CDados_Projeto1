{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ant√¥nio Amaral\n",
    "\n",
    "Nome: Gabriel Penna\n",
    "\n",
    "Nome: Caio Garcia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo Fun√ß√£o Magica iPython\n",
    "%matplotlib inline\n",
    "#Importanto Pandas\n",
    "import pandas as pd\n",
    "#Importando MatPlotLib e Numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Importando Sistema Operacional\n",
    "import os\n",
    "#Importando RE\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "/Users/antonioamaralegydiomartins/Desktop/Ant√¥nio/GitHub - Pessoal/INSPER/CDados_Projeto1/Etapa 1 e 2\n"
     ]
    }
   ],
   "source": [
    "#Checando Diret√≥rio que ser√° trabalhado:\n",
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulas Utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace (frase,tabela_rel, tabela_irrel,nao_repetentes,len_rel,len_irrel):\n",
    "    #Definindo lista de probabilidades\n",
    "    probR_list=[]\n",
    "    probIr_list=[]\n",
    "    #Separando a Frase em elementos\n",
    "    splt = frase.split()\n",
    "    #For para reconhecer a quantidade \n",
    "    for palavra in splt:\n",
    "        if palavra not in tabela_rel:\n",
    "            qtR = 1\n",
    "        else:\n",
    "            qtR = tabela_rel[palavra] + 1\n",
    "        if palavra not in tabela_irrel:\n",
    "            qtIr = 1\n",
    "        else:\n",
    "            qtIr = tabela_irrel[palavra] + 1\n",
    "        #Definindo divisores\n",
    "        div1 = len_rel + len(nao_repetentes)\n",
    "        div2 = len_irrel + len(nao_repetentes)\n",
    "        #CCalculo de Laplace\n",
    "        probR_list.append(qtR/div1)\n",
    "        probIr_list.append(qtIr/div2)\n",
    "    return (probR_list,probIr_list)\n",
    "\n",
    "def cleanup(texto):\n",
    "\n",
    "    temp = texto.lower()\n",
    "\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "\n",
    "    temp = re.sub('[()!?„Öã;:,/^~‚ôÇÔ∏è*=&-]', ' ', temp)\n",
    "\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "\n",
    "    temp = re.sub(\"[z0-9]\",\" \", temp)\n",
    "\n",
    "    temp = re.sub('\\\\\\\\\\\\\\\\n',\" \", temp)\n",
    "\n",
    "    temp = re.sub('\\\\\\\\',\" \", temp)\n",
    "\n",
    "    temp = re.sub('\\ ',\" \", temp)\n",
    "    \n",
    "    temp = re.sub(\"√©\",\"e\",temp)\n",
    "    \n",
    "    temp = re.sub(\"√£\",\"a\",temp)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo Arquivo que ser√° trabalhado\n",
    "filename = 'yakult-final_2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classifica√ß√£o 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@colchoesueli a m√©dica passou lactobacilos p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algu√©m compra yakult pra mim por deus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amanh√£ vou fazer aquele drink de morango, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomando um yakult no meio da rua üí™</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48 horas e estou sobrevivendo com;\\\\\\\\nmei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o  \\\n",
       "0    @colchoesueli a m√©dica passou lactobacilos p...            1.0   \n",
       "1            algu√©m compra yakult pra mim por deus              0.0   \n",
       "2      amanh√£ vou fazer aquele drink de morango, ...            0.0   \n",
       "3                tomando um yakult no meio da rua üí™             1.0   \n",
       "4      48 horas e estou sobrevivendo com;\\\\\\\\nmei...            1.0   \n",
       "\n",
       "   Classifica√ß√£o 2  \n",
       "0              2.0  \n",
       "1              3.0  \n",
       "2              2.0  \n",
       "3              3.0  \n",
       "4              1.0  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando Excel dentro da Vari√°vel Trainamento\n",
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classifica√ß√£o2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@otavio_amaral18 √© uma del√≠cia juro, desce...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o c√©rebro √© muito impressionante, ontem eu...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fenicolli02 quem q pede gole do yakult???...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@thamaramaia5 @adrianommartins @taaayrd @t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sdds das mamis juntas brindando yakult @fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  \\\n",
       "0      @otavio_amaral18 √© uma del√≠cia juro, desce...              1   \n",
       "1      o c√©rebro √© muito impressionante, ontem eu...              1   \n",
       "2      @fenicolli02 quem q pede gole do yakult???...              0   \n",
       "3      @thamaramaia5 @adrianommartins @taaayrd @t...              0   \n",
       "4      sdds das mamis juntas brindando yakult @fe...              0   \n",
       "\n",
       "   Classifica√ß√£o2  \n",
       "0               3  \n",
       "1               4  \n",
       "2               0  \n",
       "3               2  \n",
       "4               2  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando Excel dentro da Vari√°vel Teste\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento Naive-Bayles --- Classificador Autom√°tico de Sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto que foi escolhido para ser analizado foi o yakult, a famosa bebida fermentada japonesa, o grupo levou em considera√ß√£o a emiss√£o de opini√£o na hora de montar o seu classificador. Sendo assim se houve a emiss√£o de uma uma opini√£o, sendo ben√©fica ou n√£o, o Tweet √© considerado relevante, por√©m se houver a emiss√£o de uma opini√£o que n√£o corresponde ao produto, ou n√£o houve a emiss√£o de uma opini√£o o Tweet √© considerado irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### - Definindo Relev√¢ncia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                algu√©m compra yakult pra mim por deus  \n",
       "2          amanh√£ vou fazer aquele drink de morango, ...\n",
       "5          @madrugatina sei que vc n√£o bebe, ent√£o va...\n",
       "6          meu lindo :( quero ver ele fazendo batida ...\n",
       "7          nadei igual um desgra√ßado, agora comi bata...\n",
       "                             ...                        \n",
       "486        meu maior sonho atualmente √© um yakult veg...\n",
       "487         @sirielleina amiga e um com cor de yakult   \n",
       "492        @bcamoezi esses dias comprei couve, alface...\n",
       "495        ontem eu comi...\\\\\\\\np√£o na chapa\\\\\\\\nstak...\n",
       "497        ontem eu cheguei de madrugada em casa e fi...\n",
       "Name: Treinamento, Length: 289, dtype: object"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo quais s√£o os Tweets com classifica√ß√£o Irrelevante, dentro da Sheet Treinamento\n",
    "Irrelevantes=train.loc[train['Classifica√ß√£o']==0,'Treinamento']\n",
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @colchoesueli a m√©dica passou lactobacilos p...\n",
       "3                    tomando um yakult no meio da rua üí™ \n",
       "4          48 horas e estou sobrevivendo com;\\\\\\\\nmei...\n",
       "14         minha sogra fala mais que a mulher do yaku...\n",
       "15         √∫ltima coisa q comeu ‚Äî tomei um yakult de ...\n",
       "                             ...                        \n",
       "490        a garrafinha de yakult √© mt pequena, mano,...\n",
       "491          @caarolmario bebida de yakult com corote   \n",
       "493        acabei de ingerir isso aqui, me disseram q...\n",
       "494        bernardo aprendeu a tomar yakult de canudi...\n",
       "496      bolo: red velvet ou chocolate\\\\\\\\ndoce: chee...\n",
       "Name: Treinamento, Length: 209, dtype: object"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo quais s√£o os Tweets com classifica√ß√£o Relevante, dentro da Sheet Treinamento\n",
    "Relevantes=train.loc[train['Classifica√ß√£o']==1,'Treinamento']\n",
    "Relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### - Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando vari√°veis e realizando limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo texto_relevante, como a jun√ß√£o de todos os Tweets relevantes\n",
    "texto_relevante=' '.join(Relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo texto_irrelevante como a jun√ß√£o de todos os Tweets irrelevantes\n",
    "texto_irrelevante=' '.join(Irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passando ambos os textos pela fun√ß√£o Cleanup, e convertendo todas as letras para Lowercase\n",
    "texto_limpo_relevante=cleanup(texto_relevante).lower()\n",
    "texto_limpo_irrelevante=cleanup(texto_irrelevante).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo as strings limpas em objetos do tipo pd.series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_relevantes = texto_limpo_relevante.split()\n",
    "serie_rel = pd.Series(palavras_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = texto_limpo_irrelevante.split()\n",
    "serie_irrel = pd.Series(palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornando os objetos transformados acima em series relativas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irel = serie_rel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_rrel = serie_irrel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Irrelevantes: 1.0 e de Relevantes: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Checando porcentagem das listas\n",
    "print(\"Porcentagem de Irrelevantes: {0} e de Relevantes: {1}\".format(serie_irel.sum(),serie_rrel.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montando serie com todas as palavras que aparecem em todos os Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_rel = serie_rel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrel = serie_irrel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_rel_rel = serie_rel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_rel_irrel = serie_irrel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Somando Palavras Relevantes e Irrelevantes para criar um dicion√°rio de palavras\n",
    "todas = texto_limpo_relevante + texto_limpo_irrelevante\n",
    "#Criando serie_total\n",
    "total_palavras = todas.split()\n",
    "serie_total = pd.Series(total_palavras)\n",
    "#Criando a tabela total de palavras\n",
    "tabela_total = serie_total.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procentagem da Tabela de Irrelevantes: 4257 e de Relevantes: 3195\n"
     ]
    }
   ],
   "source": [
    "print(\"Procentagem da Tabela de Irrelevantes: {0} e de Relevantes: {1}\".format(tabela_irrel.sum(),tabela_rel.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando vari√°veis que representam a soma das tabelas irrel e rel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelPal = tabela_rel.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrrelPal = tabela_irrel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalPal = tabela_total.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrindo a Probabilidade de ser uma palavra Relevante e Irrelevante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de uma palavra ser Irrelevante: 0.571256038647343\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probI=IrrelPal/TotalPal\n",
    "print(\"A probabilidade de uma palavra ser Irrelevante: {0}\".format(probI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de uma palavra ser Relevante: 0.428743961352657\n"
     ]
    }
   ],
   "source": [
    "probR=RelPal/TotalPal\n",
    "print(\"A probabilidade de uma palavra ser Relevante: {0}\".format(probR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tabela_total = serie_total.tolist()\n",
    "nao_repetentes = set(lista_tabela_total)\n",
    "nao_repetentes = pd.DataFrame(nao_repetentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gosto muito estou viciado abri geladeira'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frase = \"gosto muito estou viciado abri geladeira\"\n",
    "Frase = cleanup(Frase).lower()\n",
    "Frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_rel = len(tabela_rel)\n",
    "len_irrel = len(tabela_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "probfR = laplace(Frase, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[0]\n",
    "probfIr = laplace(Frase, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[1]\n",
    " \n",
    "pR = 1\n",
    "pIr = 1\n",
    "\n",
    "for e in range(len(probfR)):\n",
    "    pR = pR * probfR[e]\n",
    "    pIr = pIr * probfIr[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante\n"
     ]
    }
   ],
   "source": [
    "if pR > pIr:\n",
    "    print(\"Relevante\")\n",
    "else:\n",
    "    print(\"Irrelevante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prob = []\n",
    "diver_rel = []\n",
    "Tweets = []\n",
    "for e in test[\"Teste\"]:\n",
    "    text_clean_test = cleanup(e).lower()\n",
    "    Tweets.append(text_clean_test)\n",
    "    \n",
    "List_Relevancia = []\n",
    "for Tweet in Tweets:\n",
    "    probfR2 = laplace(Tweet, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[0]\n",
    "    probfIr2 = laplace(Tweet, tabela_rel, tabela_irrel, nao_repetentes, len_rel, len_irrel)[1]\n",
    "    pR2 = 1\n",
    "    pIr2 = 1\n",
    "    for e in range(len(probfR2)):\n",
    "        pR2 = pR2 * probfR2[e]\n",
    "        pIr2 = pIr2 * probfIr2[e]\n",
    "    if pR2 > pIr2:\n",
    "        list_prob.append(pR2)\n",
    "        List_Relevancia.append(1)\n",
    "        val = pIr2/pR2\n",
    "        if val > 0.6:\n",
    "            diver_rel.append(4)\n",
    "        elif val >0.3 and val <=0.6:\n",
    "            diver_rel.append(3)\n",
    "        elif val >0 and val <=0.3:\n",
    "            diver_rel.append(2)\n",
    "    else:\n",
    "        list_prob.append(pIr2)\n",
    "        List_Relevancia.append(0)\n",
    "        val = pR2/pIr2\n",
    "        if val > 0.6:\n",
    "            diver_rel.append(0)\n",
    "        elif val >0.3 and val <=0.6:\n",
    "            diver_rel.append(1)\n",
    "        elif val >0 and val <=0.3:\n",
    "            diver_rel.append(2)\n",
    "            \n",
    "\"\"\"\n",
    "Algo que extrema import√¢ncia de citar √© a variante \"Val\" criada para dividir ambas probabilidades\n",
    "Conseguindo assim criar um fundamento para a separa√ß√£o dos Tweets por Multiplas Relev√¢ncias.\n",
    "\n",
    "O Val funciona de duas formas, sendo a primeira dela no caso de um Tweet ser considerado relevante,\n",
    "neste caso val representa a divis√£o da probabilidade desse tweet ser irrelevante pela probabilidade\n",
    "dele ser relevante, resultando em um n√∫mero menor ou igual a 1 - mas nunca maior que 1.\n",
    "A segunda forma √© parecida, e acontece quando um tweet √© Irrelevante, havendo a mudan√ßa de divisores\n",
    "na divis√£o, para novamente a variavel n√£o ultrapassar 1.\n",
    "\n",
    "Sendo assim Val representa, no primeiro caso, uma variante de relevacia que vai de 0-1, e no segundo caso\n",
    "uma variante de irrelevancia que vai de 0-1.\n",
    "\"\"\"\n",
    "\n",
    "test[\"Classificador\"] = List_Relevancia\n",
    "test[\"Probabilidade\"] = list_prob\n",
    "test[\"Multi_Classifica√ß√£o\"] = diver_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo ser√£o calculadas as porcentagens de verdadeiros/falsos positivos, e de verdadeiros/falsos negativos, junto com a acur√°cia. √â importante resaltar que ser√£o considerados relevancias de 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Verdadeiros Positivos: 33.77%\n",
      "Porcentagem de Falsos Positivos: 77.11%\n",
      "Porcentagem de Verdadeiros Negativos: 66.23%\n",
      "Porcentagem de Falsos Negativos: 22.89%\n",
      "Acur√°cia √© de: 56.25%\n"
     ]
    }
   ],
   "source": [
    "Ver_Pos = 0\n",
    "Ver_Fal = 0\n",
    "Fal_Pos = 0\n",
    "Fal_Fal = 0\n",
    "Classifica√ß√£o = []\n",
    "total_clas = pd.Series(test[\"Classifica√ß√£o\"])\n",
    "for e in total_clas:\n",
    "    Classifica√ß√£o.append(e)\n",
    "for e in range(len(Classifica√ß√£o)):\n",
    "    if Classifica√ß√£o[e] == 1:\n",
    "        if Classifica√ß√£o[e] == List_Relevancia[e]:\n",
    "            Ver_Pos+=1\n",
    "        else:\n",
    "            Ver_Fal+=1\n",
    "    else:\n",
    "        if Classifica√ß√£o[e] == List_Relevancia[e]:\n",
    "            Fal_Pos+=1\n",
    "        else:\n",
    "            Fal_Fal+=1\n",
    "Total = Ver_Pos+Ver_Fal+Fal_Pos+Fal_Fal\n",
    "Total_Pos = Ver_Pos+Ver_Fal\n",
    "Total_Fal = Fal_Pos+Fal_Fal\n",
    "#Porcentagem de Verdadeiros Positivos\n",
    "print(\"Porcentagem de Verdadeiros Positivos: {0:.2f}%\".format((Ver_Pos/Total_Pos)*100))\n",
    "#Porcentagem de Falsos Positivos\n",
    "print(\"Porcentagem de Falsos Positivos: {0:.2f}%\".format((Fal_Pos/Total_Fal)*100))\n",
    "#Porcentagem de Verdadeiros Negativos\n",
    "print(\"Porcentagem de Verdadeiros Negativos: {0:.2f}%\".format((Ver_Fal/Total_Pos)*100))\n",
    "#Porcentagem de Falsos Negativos\n",
    "print(\"Porcentagem de Falsos Negativos: {0:.2f}%\".format((Fal_Fal/Total_Fal)*100))\n",
    "#Acur√°cia\n",
    "print(\"Acur√°cia √© de: {0:.2f}%\".format((Ver_Pos+Fal_Pos)/Total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo ser√£o calculadas as porcentagens de verdadeiros/falsos positivos e de verdadeiros/falsos negativos, junto com a acur√°cia. √â importante resaltar que ser√£o consideradas todas as multiplas relev√¢ncias (Muito Relevante, Relevante, Neutro, Irrelevante, Muito Irrelevante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagens: \n",
      "==============\n",
      "Muito Relevante\n",
      "Positivo: 23.08%\n",
      "Negativo: 76.92%\n",
      "====\n",
      "Relevante\n",
      "Positivo: 2.33%\n",
      "Negativo: 97.67%\n",
      "====\n",
      "Neutro\n",
      "Positivo: 80.49%\n",
      "Negativo: 19.51%\n",
      "====\n",
      "Irrelevante\n",
      "Positivo: 8.99%\n",
      "Negativo: 91.01%\n",
      "====\n",
      "Muito Irrelevante\n",
      "Positivo: 3.23%\n",
      "Negativo: 3.23%\n",
      "====\n",
      "Acur√°cia: 25.31%\n"
     ]
    }
   ],
   "source": [
    "MRel_Pos = 0\n",
    "MRel_Fal = 0\n",
    "\n",
    "Rel_Pos = 0\n",
    "Rel_Fal = 0\n",
    "\n",
    "Neu_Pos = 0\n",
    "Neu_Fal = 0\n",
    "\n",
    "IRel_Pos = 0\n",
    "IRel_Fal = 0\n",
    "\n",
    "MIRel_Pos = 0\n",
    "MIRel_Fal = 0\n",
    "\n",
    "Classifica√ß√£o2 = []\n",
    "total_clas = pd.Series(test[\"Classifica√ß√£o2\"])\n",
    "for e in total_clas:\n",
    "    Classifica√ß√£o2.append(e)\n",
    "for e in range(len(Classifica√ß√£o2)):\n",
    "    if Classifica√ß√£o2[e] == 0:\n",
    "        if Classifica√ß√£o2[e] == diver_rel[e]:\n",
    "            MIRel_Pos+=1\n",
    "        else:\n",
    "            MIRel_Fal+=1\n",
    "    elif Classifica√ß√£o2[e] == 1:\n",
    "        if Classifica√ß√£o2[e] == diver_rel[e]:\n",
    "            IRel_Pos+=1\n",
    "        else:\n",
    "            IRel_Fal+=1\n",
    "    elif Classifica√ß√£o2[e] == 2:\n",
    "        if Classifica√ß√£o2[e] == diver_rel[e]:\n",
    "            Neu_Pos+=1\n",
    "        else:\n",
    "            Neu_Fal+=1\n",
    "    elif Classifica√ß√£o2[e] == 3:\n",
    "        if Classifica√ß√£o2[e] == diver_rel[e]:\n",
    "            Rel_Pos+=1\n",
    "        else:\n",
    "            Rel_Fal+=1\n",
    "    elif Classifica√ß√£o2[e] == 4:\n",
    "        if Classifica√ß√£o2[e] == diver_rel[e]:\n",
    "            MRel_Pos+=1\n",
    "        else:\n",
    "            MRel_Fal+=1\n",
    "Total = MRel_Pos + MRel_Fal + Rel_Pos + Rel_Fal + Neu_Pos + Neu_Fal + IRel_Pos + IRel_Fal + MIRel_Pos + MIRel_Fal\n",
    "T_MRel = MRel_Pos + MRel_Fal\n",
    "T_Rel = Rel_Pos + Rel_Fal\n",
    "T_Neu = Neu_Pos + Neu_Fal\n",
    "T_IRel = IRel_Pos + IRel_Fal\n",
    "T_MIRel = MIRel_Pos + MIRel_Fal\n",
    "\n",
    "print(\"Porcentagens: \")\n",
    "print(\"==============\")\n",
    "print(\"Muito Relevante\")\n",
    "print(\"Positivo: {0:.2f}%\".format(MRel_Pos/T_MRel*100))\n",
    "print(\"Negativo: {0:.2f}%\".format(MRel_Fal/T_MRel*100))\n",
    "print(\"====\")\n",
    "print(\"Relevante\")\n",
    "print(\"Positivo: {0:.2f}%\".format(Rel_Pos/T_Rel*100))\n",
    "print(\"Negativo: {0:.2f}%\".format(Rel_Fal/T_Rel*100))\n",
    "print(\"====\")\n",
    "print(\"Neutro\")\n",
    "print(\"Positivo: {0:.2f}%\".format(Neu_Pos/T_Neu*100))\n",
    "print(\"Negativo: {0:.2f}%\".format(Neu_Fal/T_Neu*100))\n",
    "print(\"====\")\n",
    "print(\"Irrelevante\")\n",
    "print(\"Positivo: {0:.2f}%\".format(IRel_Pos/T_IRel*100))\n",
    "print(\"Negativo: {0:.2f}%\".format(IRel_Fal/T_IRel*100))\n",
    "print(\"====\")\n",
    "print(\"Muito Irrelevante\")\n",
    "print(\"Positivo: {0:.2f}%\".format(MIRel_Pos/T_MIRel*100))\n",
    "print(\"Negativo: {0:.2f}%\".format(MIRel_Pos/T_MIRel*100))\n",
    "print(\"====\")\n",
    "print(\"Acur√°cia: {0:.2f}%\".format((MRel_Pos+Rel_Pos+Neu_Pos+IRel_Pos+MIRel_Pos)/Total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.\n",
    "\n",
    "O classificador utilizamos apresenta um problema na hora de identificar casos de dupla nega√ß√£o sarcasmo. Isso ocorre pois no sistema utilizado, todas as palavras s√£o verificadas e contabilizadas, por√©m n√£o √© poss√≠vel se descobrir a forma no qual foi dita. Isso faz com que em grande parte dos casos, as mensagens que cont√™m sarcasmo ou dupla nega√ß√£o, acabem por ser colocadas como ‚ÄúRelevantes‚Äù, pois tem uma estrutura sem√¢ntica muito semelhante ao dos exemplos que fornecemos em nosso Dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proponha um plano de expans√£o. Por que eles devem continuar financiando seu projeto?\n",
    "\n",
    "Uma vez que conseguimos realizar tal projeto com um consider√°vel n√≠vel de acerto utilizando apenas t√©cnicas mais simples, com um maior tempo e recurso, seria poss√≠vel utiliza√ß√£o de t√°ticas mais precisas, logo, aumentaria tamb√©m o √≠ndice de acerto. Sendo assim, um financiamento maior em nosso projeto √© uma garantia de uma ferramenta mais elaborada e precisa.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?\n",
    "\n",
    "Uma vez que constru√≠mos o nosso classificador, n√£o √© correto alimentar a nossa base de treinamento com o nosso pr√≥prio classificador, mas sim precisamos usar novos tweets. Isso ocorre, pois uma vez que utilizamos os mesmos, isso acabaria tendenciando o classificador, logo ele desvincularia de seu proposito original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Pense em outros cen√°rios sem intersec√ß√£o com este projeto.\n",
    "\n",
    "Existem diversos usos poss√≠veis para o uso desse tipo de classificador, o mais famoso √© a divis√£o entre ‚Äúspam‚Äù e ‚Äún√£o spam‚Äù quando vemos nosso e-mail. Al√©m desse caso, existem diversos outros ao qual podemos perceber o uso desse artificio, como por exemplo sugerir propagandas em plataformas como o youtube tendo em vista conte√∫dos consumidos anteriormente pelo usu√°rio. Em casos mais complexos, pode inclusive ajudar na medicina, ao qual eles podem prever diversas doen√ßas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer. Indique material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a medica passou lactobacilos pra vc tomar d...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alguem compra yakult pra mim por deus</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amanha vou fa er aquele drink de morango  ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomando um yakult no meio da rua üí™</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>horas e estou sobrevivendo com    meio ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>da manha eu e belle tomando yakult e comend...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>nao falei nada ai vem uma chata me responder ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>conseguiu sua merda</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>falei pro meu irmao q tava doentinha  pedi pr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>ja se envolve sabendo que se nao me der yakul...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  Classifica√ß√£o\n",
       "0       a medica passou lactobacilos pra vc tomar d...            1.0\n",
       "1              alguem compra yakult pra mim por deus              0.0\n",
       "2        amanha vou fa er aquele drink de morango  ...            0.0\n",
       "3                 tomando um yakult no meio da rua üí™              1.0\n",
       "4           horas e estou sobrevivendo com    meio ...            1.0\n",
       "..                                                 ...            ...\n",
       "814     da manha eu e belle tomando yakult e comend...            1.0\n",
       "815   nao falei nada ai vem uma chata me responder ...            1.0\n",
       "816                                conseguiu sua merda            0.0\n",
       "817   falei pro meu irmao q tava doentinha  pedi pr...            1.0\n",
       "818   ja se envolve sabendo que se nao me der yakul...            1.0\n",
       "\n",
       "[819 rows x 2 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Junta Duas pd.Series = Cria um Novo DataFrame\n",
    "    #Embaralhar de Forma Aleatoria novo DataFrame\n",
    "    #Pega Conjunto de 300 Primeiros e usa Como treinamento\n",
    "    #Pega Conjunto de 200 Depois e Usa como Teste\n",
    "    \n",
    "#Criar Listas para guardar Dados (PositivosFalsoAcur√°cia)\n",
    "\n",
    "Dados_PosPos = []\n",
    "Dados_PosFal = []\n",
    "Dados_FalPos = []\n",
    "Dados_FalFal = []\n",
    "Dados_Acurac = []\n",
    "\n",
    "Lista_Total_Classifica√ß√£o = []\n",
    "Lista_Total_Tweets = []\n",
    "for e in train[\"Classifica√ß√£o\"]:\n",
    "    Lista_Total_Classifica√ß√£o.append(e)\n",
    "for e in train[\"Treinamento\"]:\n",
    "    Lista_Total_Tweets.append(e)\n",
    "for e in test[\"Classifica√ß√£o\"]:\n",
    "    Lista_Total_Classifica√ß√£o.append(e)\n",
    "for e in test[\"Teste\"]:\n",
    "    Lista_Total_Tweets.append(e)\n",
    "    \n",
    "DataFrame = pd.DataFrame()\n",
    "DataFrame[\"Tweets\"] = Lista_Total_Tweets\n",
    "DataFrame [\"Classifica√ß√£o\"] = Lista_Total_Classifica√ß√£o\n",
    "DataFrame[\"Tweets\"] = DataFrame[\"Tweets\"].astype(object)\n",
    "lista_ = []\n",
    "for e in DataFrame[\"Tweets\"]:\n",
    "    lista_.append(cleanup(e))\n",
    "DataFrame[\"Tweets\"]=lista_\n",
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_Verdadeiros_Positivos = []\n",
    "Lista_Verdadeiros_Negativos = []\n",
    "Lista_Falsos_Positivos = []\n",
    "Lista_Falsos_Negativos = []\n",
    "Lista_Acuracia = []\n",
    "\n",
    "for e in range(0,2):\n",
    "    #Shuffle\n",
    "    DataFrame_Shuffle = DataFrame.sample(frac=1)\n",
    "    #Listas\n",
    "    Treinamento_Tweets = []\n",
    "    Teste_Tweets = []\n",
    "    Treinamento_Class = []\n",
    "    Teste_Class = []\n",
    "    List_Prob3 = []\n",
    "    List_Relevancia3 = []\n",
    "    for i in range(0,500):\n",
    "        Treinamento_Tweets.append(DataFrame[\"Tweets\"][i])\n",
    "        Treinamento_Class.append(DataFrame[\"Classifica√ß√£o\"][i])\n",
    "    for i in range(500,819):\n",
    "        Teste_Tweets.append(DataFrame[\"Tweets\"][i])\n",
    "        Teste_Class.append(DataFrame[\"Classifica√ß√£o\"][i])\n",
    "    #DataFrame para treinamento\n",
    "    DT = pd.DataFrame()\n",
    "    DT[\"Tweets\"] = Treinamento_Tweets\n",
    "    DT[\"Classifica√ß√£o\"] = Treinamento_Class\n",
    "    Relevantes = DT.loc[DT[\"Classifica√ß√£o\"]==1,\"Tweets\"]\n",
    "    Texto_Relevantes = \" \".join(Relevantes)\n",
    "    Serie_Rel = pd.Series(Texto_Relevantes)\n",
    "    IRelevantes = DT.loc[DT[\"Classifica√ß√£o\"]==0,\"Tweets\"]\n",
    "    Texto_IRelevantes = \" \".join(IRelevantes)\n",
    "    Serie_IRel = pd.Series(Texto_IRelevantes)\n",
    "        #Split()\n",
    "    spl_Rel = Texto_Relevantes.split()\n",
    "    spl_IRel = Texto_IRelevantes.split()\n",
    "        #Criando Tabelas\n",
    "    Tabela_Rel = Serie_Rel.value_counts()\n",
    "    Tabela_Irrel = Serie_IRel.value_counts()\n",
    "       #Criando Total\n",
    "    Todas = spl_Rel+spl_IRel\n",
    "    Serie_Total = pd.Series(Todas)\n",
    "    Tabela_Total = Serie_Total.value_counts()\n",
    "    Lista_Tabela_Total = Serie_Total.tolist()\n",
    "    Nao_Repete = set(Lista_Tabela_Total)\n",
    "    Nao_Repete = pd.DataFrame(Nao_Repete)\n",
    "        #Definindo Len\n",
    "    Len_Rel = len(tabela_rel)\n",
    "    Len_Irrel = len(tabela_irrel)\n",
    "    #DataFrame para Teste\n",
    "    DT2 = pd.DataFrame()\n",
    "    DT2[\"Tweets\"] = Teste_Tweets\n",
    "    DT2[\"Classifi√ß√£o\"] = Teste_Class\n",
    "        #LapLace\n",
    "    for Tweet in Teste_Tweets:\n",
    "        probfR3 = laplace (Tweet, Tabela_Rel, Tabela_Irrel, Nao_Repete, Len_Rel, Len_Irrel)[0]\n",
    "        probfIr3 = laplace (Tweet, Tabela_Rel, Tabela_Irrel, Nao_Repete, Len_Rel, Len_Irrel)[1]\n",
    "        pR3 = 1\n",
    "        pIr3 = 1\n",
    "        for e in range(len(probfR3)):\n",
    "            pR3 = pR3 * probfR3[e]\n",
    "            pIr3 = pIr3 * probfIr3[e]\n",
    "        if pR3 > pIr3:\n",
    "            List_Prob3.append(pR3)\n",
    "            List_Relevancia3.append(1)\n",
    "        else:\n",
    "            print(\"Humberto √© corno\")\n",
    "            List_Prob3.append(pIr3)\n",
    "            List_Relevancia3.append(0)\n",
    "    Ver_Pos3 = 0\n",
    "    Ver_Fal3 = 0\n",
    "    Fal_Pos3 = 0\n",
    "    Fal_Fal3 = 0\n",
    "    Classifica√ß√£o3 = []\n",
    "    total_clas3 = pd.Series(DT2[\"Classifi√ß√£o\"])\n",
    "    for e in total_clas3:\n",
    "        Classifica√ß√£o3.append(e)\n",
    "    for e in range(len(Classifica√ß√£o3)):\n",
    "        if Classifica√ß√£o3[e] == 1:\n",
    "            if Classifica√ß√£o3[e] == List_Relevancia3[e]:\n",
    "                Ver_Pos3+=1\n",
    "            else:\n",
    "                Ver_Fal3+=1\n",
    "        else:\n",
    "            if Classifica√ß√£o3[e] == List_Relevancia3[e]:\n",
    "                Fal_Pos3+=1\n",
    "            else:\n",
    "                Fal_Fal3+=1\n",
    "    Total3 = Ver_Pos3+Ver_Fal3+Fal_Pos3+Fal_Fal3\n",
    "    Total_Pos3 = Ver_Pos3+Ver_Fal3\n",
    "    Total_Fal3 = Fal_Pos3+Fal_Fal3\n",
    "    Lista_Verdadeiros_Positivos.append(Ver_Pos3/Total_Pos3*100)\n",
    "    Lista_Verdadeiros_Negativos.append(Fal_Pos/Total_Fal*100)\n",
    "    Lista_Falsos_Positivos.append(Ver_Fal/Total_Pos*100)\n",
    "    Lista_Falsos_Negativos.append(Fal_Fal/Total_Fal*100)\n",
    "    Lista_Acuracia.append((Ver_Pos+Fal_Pos)/Total*100)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle\n",
    "DataFrame_Shuffle = DataFrame.sample(frac=1)\n",
    "#Listas\n",
    "Treinamento_Tweets = []\n",
    "Teste_Tweets = []\n",
    "Treinamento_Class = []\n",
    "Teste_Class = []\n",
    "List_Prob3 = []\n",
    "List_Relevancia3 = []\n",
    "for i in range(0,500):\n",
    "    Treinamento_Tweets.append(DataFrame[\"Tweets\"][i])\n",
    "    Treinamento_Class.append(DataFrame[\"Classifica√ß√£o\"][i])\n",
    "for i in range(500,819):\n",
    "    Teste_Tweets.append(DataFrame[\"Tweets\"][i])\n",
    "    Teste_Class.append(DataFrame[\"Classifica√ß√£o\"][i])\n",
    "    \n",
    "DT3 = pd.DataFrame()\n",
    "DT3[\"Treinamento\"] = Treinamento_Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 100.0]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lista_Verdadeiros_Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-364-c9c33c6e6675>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-364-c9c33c6e6675>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    DT2 = pd.DataFrame()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " #DataFrame para Teste\n",
    "    DT2 = pd.DataFrame()\n",
    "    DT2[\"Tweets\"] = Teste_Tweets\n",
    "    DT2[\"Classifi√ß√£o\"] = Teste_Class\n",
    "    TRelevantes = DT2.loc[DT2[\"Classifica√ß√£o\"]==1,\"Tweets\"]\n",
    "    TIRelevantes = DT2.loc[DT2[\"Classifica√ß√£o\"]==0,\"Tweets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
